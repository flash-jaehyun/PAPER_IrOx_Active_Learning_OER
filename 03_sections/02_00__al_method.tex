% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% | - Active Learning Machine Learning Methodology
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Outline:
%   * PARAGRAPH 00
%     - General introduction and high-level overview of algorithm
%   * PARAGRAPH 01
%     - Candidate space generation methodology
%   * PARAGRAPH 02
%     - Quick paragraph about structure featurization
%   * PARAGRAPH 03
%     - Iterative AL algorithm procedure
%   * PARAGRAPH 04
%
%
%
%   * There will not be much motivation for our general approach from the introduction, so this is a good place to more properly layout our arguments
%
% Points to mention:
%   * Active learning frameworks are a means by which to generate the most valuable training data set, on the fly.
%   * The search space of materials is not a continuous space but a discrete array of individual structures
% __|
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% | - PARAGRAPH HEADER
% General intro to AL scheme
%
% __|
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% | - PARAGRAPH BODY
%
Our approach utilizes an active learning framework and surrogate models,
whereby a regression model is trained on a set of candidate materials by iteratively and intelligently sampling structures from a candidate set.
%
% is presented in Figure~\ref{fig:all_diagram}.
Figure~\ref{fig:all_diagram} shows a schematic overview of our AL methodology.
%
There are two primary components of the algorithm, the first (Figure~\ref{fig:all_diagram}a) is the generation of the candidate space,
which defines the list of candidate crystal structures to be searched through.
%
The second component is the iterative search through candidate space via a continuously retrained surrogate model, (Figure~\ref{fig:all_diagram}.b).
% __|
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% =========================================================
% FIGURE ==================================================
% | - Figure | Active Learning Algorithm ******************
\begin{figure*}
\centering
\includegraphics[width=0.5\textwidth]{02_figures/al_diagram/Active_learning_diagram__v2.pdf}
\caption{\label{fig:all_diagram}
%
% Probably better to keep this caption really concise and refer to the text
Process flow diagram for the active learning accelerated algorithm. The procedure is composed of
(a) generation of the candidate set of considered crystal structures constructed from DFT materials databases and
(b) iterative active learning surrogate search of the candidate space.
}
\end{figure*}
% __|
% =========================================================


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% | - PARAGRAPH HEADER
% CANDIDATE SPACE GENERATION
%
% __|
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% | - PARAGRAPH BODY
%
%The generation of the candidate space is a critical step in the discovery of novel crystal structures for a given system,
%since the initial candidate pool determines which structures that can ultimately be discovered, it is imperative to construct candidates that are sufficiently diverse, such that they encompass as much of the structural diversity in the PES as possible.
%
% TODO PENDING Ask @Ankit for these numbers
% The MP project number should be correct, but the OQMD number might be wrong
% MP{AB2: 2424, AB3: 2341} | OQMD{AB2: 4736, AB3: 28883}
The candidate structure datasets for \IrOtwo and \IrOthree were constructed by first obtaining all \ABtwo and \ABthree structures in the Materials Project\cite{Jain2013} and OQMD\cite{Kirklin2015} databases
(in total \num{4528} \ABtwo and \num{23764} \ABthree entries).
%
To reduce the size of the candidate space while maintaining maximum structural diversity, structurally redundant systems were removed via a space group based structural classification scheme developed by Jain \latin{et al.} \cite{Jain2018}.
%
In short, a materials structural identity is defined by a unique combination of the element-nonspecific stoichiometry (\ABtwo, \ABthree, etc.), space group symmetry and Wyckoff positions, and are referred to as a materials structural prototype.
%
% This is my attempt to further clarify the previous sentence
Structures that share these properties are considered identical.
%
For example, the \num{300000} entry dataset of \ABOthree style perovskites in OQMD, which only differ by the choice of elements for A, B, and C, all belong to the same structural prototype, and are thus structurally equivalent.
%
Eliminating these redundant systems from the materials databases reduces the number of entries to \num{697} and \num{259} structures for the \ABtwo and \ABthree stoichiometries, respectively.
%
%The orders of magnitude reduction between all structures and unique structures highlights the lack of structural diversity in the OQMD and MP databases.
This reduction leads to orders of magnitude reduction of the search space, as opposed to full utilization of the OQMD and Materials Project databases.
%
Finally, only structures containing $\leq\num{75}$ atoms
(\num{567} and \num{256} \ABtwo and \ABthree structures respectively)
were included to the reduce the computational expense of subsequent DFT calculations.
%
We next substituted iridium and oxygen for the A and B sites, and these Ir-O adapted polymorphs were isotropically relaxed to accommodate their atomic radii.
%
A full bulk DFT optimization recipe was performed on these systems,
yielding a data set of \num{736} relaxed bulk \IrOx polymorphs
(\num{487} and \num{249} structures for \IrOtwo and \IrOthree, respectively),
after discarding 87 non-converged structures.
%
While not particularly large, our candidate space's size allows us to tractably compute all DFT optimized structures, thus allowing us to benchmark the performance of our methodology.
%
The full details of the candidate space generation and DFT calculations are in the Supplementary Information.
% __|
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% | - Featurization Strategy
% Short paragraph on Voronoi featurization
% __|
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% | - PARAGRAPH BODY
%
The active learning algorithm proceeds through a structure featurization scheme based on Voronoi tessellation developed by Ward \latin{et al.} \cite{Ward2017} which produces a \num{271} length fingerprint vector that is invariant to isotropic lattice changes and somewhat insensitive to the precise atomic coordinates.
%
These fingerprints encode both chemical and structural information by constructing attributes from elemental properties which are weighted by the local environment of the structure via the construction of the Wigner-Seitz cell.
\cite{Wigner1933}
%
We applied the active learning model to the \IrOtwo and \IrOthree spaces separately, i.e. at fixed stoichiometry, which further reduces the \num{271} length fingerprint vector to \num{101} non-zero variance features.
%significantly reducing the dimensionality of the features.
%
% TODO Create cross-validation plot
Further dimensionality reduction was achieved via a principle component analysis (PCA) \cite{Tipping1999}, which was used to reduce the remaining \num{101} fingerprints to \num{10}.
%
\num{10} PCA components demonstrated the optimal cross-validation mean absolute error (MAE), although only capturing 80\% of the fingerprint's variance (see \ref{fig:cv_anal}).
% __|
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% | - PARAGRAPH HEADER
% Active Learning Loop
%
% NOTE This paragraph is a bit long, find way to split into 2
% __|
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% | - PARAGRAPH BODY
%
The active learning algorithm proceeds through iterative generations of ML training, prediction, and acquisition steps that are visualized in Figure~\ref{fig:all_diagram}b.
%
% COMBAK Did I get all of the important features of GP here? @Jose
To start, we utilized Gaussian process (GP) regression with an RBF kernel as implemented in CatLearn~\cite{hansen2019atomistic,CatLearn_Repo} due to their highly flexible fits and built-in uncertainty quantification.
%
% NOTE I've introduced the aquis. crit. with the GP uncertainty before talking about aquis. in more detail, need to restructure
%
At the first generation, the model is trained on randomly sampled candidates,
and is then used to predict the formation enthalpy (\DHf) of all structures in the candidate space.
%
This predicted energy landscape is then used to choose the next systems to acquire (calculate via DFT) by selecting systems that minimize the GP-UCB (Gaussian process lower confidence bound) acquisition function,
$U = \mu - \kappa \sigma$~\cite{Cox1992}.
%
Here, $\mu$ and $\sigma$ are the predicted \DHf mean and uncertainty, respectively,
and $\kappa$ is a parameter that weights exploitation vs exploration of the search-space (set to 1).
%
At every generation of the AL loop, $N$ systems that minimize the acquisition function are acquired for DFT optimization and are subsequently added to the training data set, where $N$ is AL bin size (here set to 5).
%
% TODO N is used into mean number of atoms (FIX)
The value of $N$ determines how many structures are selected for DFT calculations,
and as such, determines the degree of parallelization of the routine.
%
% The optimal value of $N$ depends on the computational resources available, as small values can result in slow down the discovery rate of the AL algorithm,
% as every DFT calculation needs to be performed more serially.
%
% TODO: Is this statement true?
% Larger values of $N$ speed up the active-learning algorithm, but leads to a higher number of DFT calculations performed before convergence.
%
% COMBAK We are discussing alternative convergence criteria, or whether to even have convergence criteria here
% I think this is fine, just mention a few possible convergence criteria and leave at that
In practice, the AL algorithm proceeds until no more stable polymorphs are found, or after the allocated computational budget is exhausted.
% convergence is achieved, which here is chosen to be the generation at which the structures within the range of metastability, here taken as \num{0.1} eV/atom, are unchanging over three consecutive generations.
% __|
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% | - Duplicate Structure Removal
%
% __|
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% | - PARAGRAPH BODY
%
Although initially unique, the structures in the candidate set often relax into one another over the course of the DFT optimization, introducing duplicates in the post-DFT structures.
%
The duplicates are removed, on the fly, during each generation of the AL algorithm
by using the structure similarity quantification method of Su \latin{et al.}~\cite{Su2017}.
%
% The coordination characterization function (CCF) based methodology to quantify the similarity between structures was used to identify and remove duplicate structures.\cite{Su2017}
% __|
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
