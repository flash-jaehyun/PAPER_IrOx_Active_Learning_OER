# R40
@article{Jain2018,
author = {Jain, Ankit},
doi = {10.1103/PhysRevB.98.214112},
file = {:C$\backslash$:/Users/raulf2012/Dropbox/01{\_}norskov/01{\_}projects/04{\_}irox{\_}oer{\_}orr/02{\_}lit{\_}refs/40{\_}PhysRevB.98.214112.pdf:pdf},
keywords = {doi:10.1103/PhysRevB.98.214112 url:https://doi.org/10.1103/PhysRevB.98.214112},
pages = {1--7},
publisher = {American Physical Society},
title = {{PHYSICAL REVIEW B 98 , 214112 ( 2018 ) Atomic-position independent descriptor for machine learning of material properties}},
volume = {214112},
year = {2018}
}

@article{schlexer2019machine,
  title={Machine learning for computational heterogeneous catalysis},
  author={Schlexer Lamoureux, Philomena and Winther, Kirsten T and Garrido Torres, Jose Antonio and Streibel, Verena and Zhao, Meng and Bajdich, Michal and Abild-Pedersen, Frank and Bligaard, Thomas},
  journal={ChemCatChem},
  volume={11},
  number={16},
  pages={3581--3601},
  year={2019},
  publisher={Wiley Online Library}
}

@article{mamun2019high,
  title={High-throughput calculations of catalytic properties of bimetallic alloy surfaces},
  author={Mamun, Osman and Winther, Kirsten T and Boes, Jacob R and Bligaard, Thomas},
  journal={Scientific data},
  volume={6},
  number={1},
  pages={1--9},
  year={2019},
  publisher={Nature Publishing Group}
}

# R48
@article{Ward2017,
abstract = {{\textcopyright} 2017 American Physical Society. While high-throughput density functional theory (DFT) has become a prevalent tool for materials discovery, it is limited by the relatively large computational cost. In this paper, we explore using DFT data from high-throughput calculations to create faster, surrogate models with machine learning (ML) that can be used to guide new searches. Our method works by using decision tree models to map DFT-calculated formation enthalpies to a set of attributes consisting of two distinct types: (i) composition-dependent attributes of elemental properties (as have been used in previous ML models of DFT formation energies), combined with (ii) attributes derived from the Voronoi tessellation of the compound's crystal structure. The ML models created using this method have half the cross-validation error and similar training and evaluation speeds to models created with the Coulomb matrix and partial radial distribution function methods. For a dataset of 435 000 formation energies taken from the Open Quantum Materials Database (OQMD), our model achieves a mean absolute error of 80 meV/atom in cross validation, which is lower than the approximate error between DFT-computed and experimentally measured formation enthalpies and below 15{\%} of the mean absolute deviation of the training set. We also demonstrate that our method can accurately estimate the formation energy of materials outside of the training set and be used to identify materials with especially large formation enthalpies. We propose that our models can be used to accelerate the discovery of new materials by identifying the most promising materials to study with DFT at little additional computational cost.},
author = {Ward, Logan and Liu, Ruoqian and Krishna, Amar and Hegde, Vinay I. and Agrawal, Ankit and Choudhary, Alok and Wolverton, Chris},
doi = {10.1103/PhysRevB.96.024104},
issn = {24699969},
journal = {Physical Review B},
title = {{Including crystal structure attributes in machine learning models of formation energies via Voronoi tessellations}},
year = {2017}
}

# R55
@article{Jennings2019,
abstract = {Materials discovery is increasingly being impelled by machine learning methods that rely on pre-existing datasets. Where datasets are lacking, unbiased data generation can be achieved with genetic algorithms. Here a machine learning model is trained on-the-fly as a computationally inexpensive energy predictor before analyzing how to augment convergence in genetic algorithm-based approaches by using the model as a surrogate. This leads to a machine learning accelerated genetic algorithm combining robust qualities of the genetic algorithm with rapid machine learning. The approach is used to search for stable, compositionally variant, geometrically similar nanoparticle alloys to illustrate its capability for accelerated materials discovery, e.g., nanoalloy catalysts. The machine learning accelerated approach, in this case, yields a 50-fold reduction in the number of required energy calculations compared to a traditional “brute force” genetic algorithm. This makes searching through the space of all homotops and compositions of a binary alloy particle in a given structure feasible, using density functional theory calculations.},
author = {Jennings, Paul C. and Lysgaard, Steen and Hummelsh{\o}j, Jens Strabo and Vegge, Tejs and Bligaard, Thomas},
doi = {10.1038/s41524-019-0181-4},
file = {:C$\backslash$:/Users/raul{\_}desktop/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jennings et al. - 2019 - Genetic algorithms for computational materials discovery accelerated by machine learning.pdf:pdf},
issn = {2057-3960},
journal = {npj Computational Materials},
keywords = {Computational methods,Nanoparticles,Theoretical chemistry},
mendeley-groups = {Dr. Norksov/irox{\_}ml{\_}oer},
month = {dec},
number = {1},
pages = {46},
publisher = {Nature Publishing Group},
title = {{Genetic algorithms for computational materials discovery accelerated by machine learning}},
url = {http://www.nature.com/articles/s41524-019-0181-4},
volume = {5},
year = {2019}
}
@article{torres2019low,
  title={Low-Scaling Algorithm for Nudged Elastic Band Calculations Using a Surrogate Machine Learning Model},
  author={Torres, Jos{\'e} A Garrido and Jennings, Paul C and Hansen, Martin H and Boes, Jacob R and Bligaard, Thomas},
  journal={Physical review letters},
  volume={122},
  number={15},
  pages={156001},
  year={2019},
  publisher={APS}
}

# R60
@article{hansen2019atomistic,
  title={An Atomistic Machine Learning Package for Surface Science and Catalysis},
  author={Hansen, Martin Hangaard and Torres, Jos{\'e} A Garrido and Jennings, Paul C and Wang, Ziyun and Boes, Jacob R and Mamun, Osman G and Bligaard, Thomas},
  journal={arXiv preprint arXiv:1904.00904},
  year={2019}
}

# Direct CatLearn reference
@misc{CatLearn_Repo,
title={{CatLearn: An environment for atomistic machine learning in Python for applications in catalysis}},
year=2019,
doi={10.5281/zenodo.15991},
version={0.6.1},
url={https://github.com/SUNCAT-Center/CatLearn}
}

# R101
@inproceedings{Cox1992,
abstract = {An algorithm for finding global optima using statistical prediction is presented. Assuming a random function model, lower confidence bounds on predicted values are used for sequential selection of evaluation points and as a convergence criterion. Performance comparision with published results on several test functions indicate that the procedure is very efficient in finding the global optimum of a multimodal function, and in terminating with relatively few evaluations.},
author = {Cox, Dennis D. and John, Susan},
booktitle = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
doi = {10.1109/ICSMC.1992.271617},
isbn = {0780307208},
issn = {1062922X},
mendeley-groups = {Dr. Norksov/irox{\_}ml{\_}oer},
pages = {1241--1246},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{A statistical method for global optimization}},
volume = {1992-Janua},
year = {1992}
}

# R98
@misc{Graser2018,
abstract = {Predicting crystal structure has always been a challenging problem for physical sciences. Recently, computational methods have been built to predict crystal structure with success but have been limited in scope and computational time. In this paper, we review computational methods such as density functional theory and machine learning methods used to predict crystal structure. We also explored the breadth versus accuracy of building a model to predict across any crystal structure using machine learning. We extracted 24913 unique chemical formulas existing between 290 and 310 K from the Pearson Crystal Database. Of these 24913 formulas, there exists 10711 unique crystal structures referred to as entry prototypes. Common entries might have hundreds of chemical compositions, while the vast majority of entry prototypes is represented by fewer than ten unique compositions. To include all data in our predictions, entry prototypes that lacked a minimum number of representatives were relabeled as "Other". By selecting the minimum numbers to be 150, 100, 70, 40, 20, and 10, we explored how limiting class sizes affected performance. Using each minimum number to reorganize the data, we looked at the classification performance metrics: accuracy, precision, and recall. Accuracy ranged from 97 ± 2 to 85 ± 2{\%}; average precision ranged from 86 ± 2 to 79 ± 2{\%}, while average recall ranged from 73 ± 2 to 54 ± 2{\%} for minimum-class representatives from 150 to 10, respectively.},
author = {Graser, Jake and Kauwe, Steven K. and Sparks, Taylor D.},
booktitle = {Chemistry of Materials},
doi = {10.1021/acs.chemmater.7b05304},
file = {:home/raulf2012/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Graser, Kauwe, Sparks - 2018 - Machine Learning and Energy Minimization Approaches for Crystal Structure Predictions A Review and New Ho.pdf:pdf},
issn = {15205002},
mendeley-groups = {Dr. Norksov/irox{\_}ml{\_}oer},
month = {jun},
number = {11},
pages = {3601--3612},
publisher = {American Chemical Society},
title = {{Machine Learning and Energy Minimization Approaches for Crystal Structure Predictions: A Review and New Horizons}},
url = {https://pubs.acs.org/doi/10.1021/acs.chemmater.7b05304},
volume = {30},
year = {2018}
}

# R106
@article{Bassman2018,
abstract = {Hetero-structures made from vertically stacked monolayers of transition metal dichalcogenides hold great potential for optoelectronic and thermoelectric devices. Discovery of the optimal layered material for specific applications necessitates the estimation of key material properties, such as electronic band structure and thermal transport coefficients. However, screening of material properties via brute force ab initio calculations of the entire material structure space exceeds the limits of current computing resources. Moreover, the functional dependence of material properties on the structures is often complicated, making simplistic statistical procedures for prediction difficult to employ without large amounts of data collection. Here, we present a Gaussian process regression model, which predicts material properties of an input hetero-structure, as well as an active learning model based on Bayesian optimization, which can efficiently discover the optimal hetero-structure using a minimal number of ab initio calculations. The electronic band gap, conduction/valence band dispersions, and thermoelectric performance are used as representative material properties for prediction and optimization. The Materials Project platform is used for electronic structure computation, while the BoltzTraP code is used to compute thermoelectric properties. Bayesian optimization is shown to significantly reduce the computational cost of discovering the optimal structure when compared with finding an optimal structure by building a regression model to predict material properties. The models can be used for predictions with respect to any material property and our software, including data preparation code based on the Python Materials Genomics (PyMatGen) library as well as python-based machine learning code, is available open source.},
author = {Bassman, Lindsay and Rajak, Pankaj and Kalia, Rajiv K. and Nakano, Aiichiro and Sha, Fei and Sun, Jifeng and Singh, David J. and Aykol, Muratahan and Huck, Patrick and Persson, Kristin and Vashishta, Priya},
doi = {10.1038/s41524-018-0129-0},
file = {:C$\backslash$:/Users/raul{\_}desktop/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bassman et al. - 2018 - Active learning for accelerated design of layered materials.pdf:pdf},
issn = {20573960},
journal = {npj Computational Materials},
keywords = {Chemical engineering,Computational methods},
mendeley-groups = {Dr. Norksov/irox{\_}ml{\_}oer},
month = {dec},
number = {1},
pages = {1--9},
publisher = {Nature Publishing Group},
title = {{Active learning for accelerated design of layered materials}},
volume = {4},
year = {2018}
}

# R107
@article{Montoya2020,
author = "Joseph H. Montoya and Kirsten Winther and Raul A. Flores and Thomas Bligaard and Jens Strabo Hummelshøj and Muratahan Aykol",
title = "{Autonomous Intelligent Agents for Accelerated Materials Discovery}",
year = "2020",
month = "2",
url = "https://chemrxiv.org/articles/Autonomous_Intelligent_Agents_for_Accelerated_Materials_Discovery/11860104",
doi = "10.26434/chemrxiv.11860104.v1"
}
